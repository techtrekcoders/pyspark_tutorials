{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e7c2c64-8306-47ee-a856-ad004f36e8ea",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# PySpark SQL `where()` Function: SQL-like Filtering Made Easy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36a88e6c-846e-4449-b035-a3a224bc01a4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Introduction to the `where()` Function\n",
    "\n",
    "The `where()` function in PySpark is used to filter rows based on a condition, similar to the SQL `WHERE` clause. Itâ€™s essentially identical to the `filter()` function but written in a more SQL-like syntax.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec8937ef-2394-4620-bdab-bc1964a53d59",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Basic Syntax:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba5c44b2-5649-4dc0-a1fc-4e88123b0216",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "```\n",
    "DataFrame.where(condition)\n",
    "```\n",
    "\n",
    "The condition can be any valid PySpark SQL expression that evaluates to True or False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27d9dd22-bf35-4c53-8242-081e936a96a7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Why Use `where()`?\n",
    "\n",
    "Although `where()` and `filter()` are interchangeable, some developers prefer `where()` for SQL-like syntax consistency when writing queries or when transitioning from SQL-based data environments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4845e059-bcb5-41ed-a294-26bae030ff39",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Practical Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5572fbc-1470-4380-9c84-1539184cbba6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1. Basic SQL-like Filtering\n",
    "\n",
    "**Scenario**: You have a DataFrame with employee salary data, and you want to select employees who earn more than $3,000.\n",
    "\n",
    "**Code Example**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf60a906-7bfe-405a-b92e-581a5461b190",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+------+\n|EMPLOYEE_ID|NAME|SALARY|\n+-----------+----+------+\n|          2|Jane|  4000|\n|          3| Tom|  3500|\n+-----------+----+------+\n\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([\n",
    "    (1, \"John\", 2500),\n",
    "    (2, \"Jane\", 4000),\n",
    "    (3, \"Tom\", 3500)\n",
    "], [\"EMPLOYEE_ID\", \"NAME\", \"SALARY\"])\n",
    "\n",
    "# SQL-like filtering: where SALARY > 3000\n",
    "df.where(\"SALARY > 3000\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33e41464-713b-4926-8d17-01c077ee16b3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2. Filtering Using Multiple Conditions\n",
    "\n",
    "**Scenario**: You want to filter employees whose salary is between $3,000 and $4,000.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "981b057c-a091-499b-9097-30630c670a68",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+------+\n|EMPLOYEE_ID|NAME|SALARY|\n+-----------+----+------+\n|          3| Tom|  3500|\n+-----------+----+------+\n\n"
     ]
    }
   ],
   "source": [
    "# SQL-like filtering: where SALARY between 3000 and 4000\n",
    "df.where(\"SALARY > 3000 AND SALARY < 4000\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4dcc61c-2d85-47a9-bd2d-065c2e2cb3cc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3. String-Based Filtering\n",
    "\n",
    "**Scenario**: You want to filter employees whose names start with the letter \"J.\"\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4961d5cd-7f5d-45cd-9c32-e07fa220d66a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+------+\n|EMPLOYEE_ID|NAME|SALARY|\n+-----------+----+------+\n|          1|John|  2500|\n|          2|Jane|  4000|\n+-----------+----+------+\n\n"
     ]
    }
   ],
   "source": [
    "# SQL-like filtering: where NAME starts with 'J'\n",
    "df.where(\"NAME LIKE 'J%'\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b39aba1-4de9-49c8-b44f-bd4cf449249c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4. Filtering Using Multiple Columns\n",
    "\n",
    "**Scenario**: You want to filter employees whose salary is greater than $3,000 and whose name starts with \"T.\"\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1435f01b-64b0-41c7-8ccf-7aa3bd86247a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+------+\n|EMPLOYEE_ID|NAME|SALARY|\n+-----------+----+------+\n|          3| Tom|  3500|\n+-----------+----+------+\n\n"
     ]
    }
   ],
   "source": [
    "# SQL-like filtering: where SALARY > 3000 and NAME starts with 'T'\n",
    "df.where(\"SALARY > 3000 AND NAME LIKE 'T%'\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dbb947c4-aaa8-4aae-959f-06324d1f3aec",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5. Filtering Null and Not Null Values\n",
    "\n",
    "**Scenario**: You want to filter rows where the `Salary` column is null or not null.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b387ab6d-a9a9-4f66-abce-22cd8e759eb5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+------+\n|EMPLOYEE_ID|NAME|SALARY|\n+-----------+----+------+\n|          1|John|  2500|\n|          3| Tom|  3500|\n+-----------+----+------+\n\n+-----------+----+------+\n|EMPLOYEE_ID|NAME|SALARY|\n+-----------+----+------+\n|          2|Jane|  null|\n+-----------+----+------+\n\n"
     ]
    }
   ],
   "source": [
    "df_with_null = spark.createDataFrame([\n",
    "    (1, \"John\", 2500),\n",
    "    (2, \"Jane\", None),\n",
    "    (3, \"Tom\", 3500)\n",
    "], [\"EMPLOYEE_ID\", \"NAME\", \"SALARY\"])\n",
    "\n",
    "# SQL-like filtering: where SALARY is not null\n",
    "df_with_null.where(\"SALARY IS NOT NULL\").show()\n",
    "\n",
    "# SQL-like filtering: where SALARY is null\n",
    "df_with_null.where(\"SALARY IS NULL\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5ab2872-8649-4a77-9e6a-e1f82a5a4c25",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 6. Combining SQL-like Filtering with Expressions\n",
    "\n",
    "**Scenario**: You want to filter employees whose salary, after a 10% increase, will exceed $3,500.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0bb346d-62cd-492a-a6e2-b14d096f0828",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+------+\n|EMPLOYEE_ID|NAME|SALARY|\n+-----------+----+------+\n|          2|Jane|  4000|\n|          3| Tom|  3500|\n+-----------+----+------+\n\n"
     ]
    }
   ],
   "source": [
    "# SQL-like filtering: where (SALARY * 1.1) > 3500\n",
    "df.where(\"(SALARY * 1.1) > 3500\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "29d04dd9-83b9-4b6f-b6bb-16f6b467e093",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 7. Using `where()` with PySpark Expressions\n",
    "\n",
    "**Scenario**: You prefer to use PySpark column expressions in your filtering logic.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a602eda9-d042-4ce8-8837-555de870015f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+------+\n|EMPLOYEE_ID|NAME|SALARY|\n+-----------+----+------+\n|          3| Tom|  3500|\n+-----------+----+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Using PySpark column expressions in where()\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df.where((col(\"SALARY\") > 3000) & (col(\"SALARY\") < 4000)).show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3_pyspark_where_function_sql_like_filtering_made_easy",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
