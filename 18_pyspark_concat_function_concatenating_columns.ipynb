{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b6c262e-6f72-48da-88e8-b0dddc06630b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# PySpark SQL concat() Function: Concatenating Columns Made Simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0cfa2956-2c04-4b80-ba70-314a6eafb1c6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Introduction to the `concat()` Function\n",
    "\n",
    "The `concat()` function in PySpark is used to concatenate multiple columns or expressions into a single column. It is similar to concatenation functions in other programming languages and SQL, where you combine two or more strings (or columns) into one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c3cfa86-ed05-4e65-9610-fc016160daaf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Basic Syntax:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7180f9ac-cf7c-4c79-af70-7e66aa88766d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "```\n",
    "from pyspark.sql.functions import concat\n",
    "\n",
    "DataFrame.select(concat(column1, column2, ...).alias(\"new_column\"))\n",
    "```\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "- **`column1, column2`**: The columns you want to concatenate.\n",
    "- You can also concatenate string literals or expressions with columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7482a732-23a7-4624-904b-7081fc5faec2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Why Use `concat()`?\n",
    "\n",
    "- It is useful when you need to combine multiple columns into one, such as merging first and last names, joining city and state fields, or combining various string-based identifiers into a single column.\n",
    "- `concat()` is often used when preparing data for display, reporting, or exporting as combined information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e167b9e3-40d1-4a04-acb7-b6251db76ced",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Practical Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82b42888-e300-43b2-90b8-91c09b309f03",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1. Concatenating Two Columns\n",
    "\n",
    "**Scenario**: You have a DataFrame with first and last names, and you want to concatenate them into a full name.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b5036af-4fe3-452d-b1b3-c0b2c7a77060",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n|full_name|\n+---------+\n|  JohnDoe|\n|JaneSmith|\n| TomBrown|\n+---------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat\n",
    "\n",
    "df = spark.createDataFrame([\n",
    "    (\"John\", \"Doe\"),\n",
    "    (\"Jane\", \"Smith\"),\n",
    "    (\"Tom\", \"Brown\")\n",
    "], [\"first_name\", \"last_name\"])\n",
    "\n",
    "# Concatenate first_name and last_name into full_name\n",
    "df.select(concat(df.first_name, df.last_name).alias(\"full_name\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa8eb41c-abc9-44bb-9ba5-910e010c6940",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2. Concatenating with a Separator\n",
    "\n",
    "**Scenario**: You want to concatenate `FirstName` and `LastName` with a space in between.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77d15526-05cf-44c7-b712-afe0a125606c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n| full_name|\n+----------+\n|  John Doe|\n|Jane Smith|\n| Tom Brown|\n+----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# Concatenate first_name and last_name with a space in between\n",
    "df.select(concat(df.first_name, lit(\" \"), df.last_name).alias(\"full_name\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b3fbdcc-5d00-4a5c-9441-b16780466ff3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3. Concatenating Multiple Columns\n",
    "\n",
    "**Scenario**: You have a DataFrame with multiple address fields, and you want to concatenate them into a full address.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a470b313-35fd-45a4-a32b-42003128d3d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+\n|full_address                     |\n+---------------------------------+\n|123 Main St, City, State 12345   |\n|456 Broadway, City2, State2 67890|\n+---------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df_address = spark.createDataFrame([\n",
    "    (\"123\", \"Main St\", \"City\", \"State\", \"12345\"),\n",
    "    (\"456\", \"Broadway\", \"City2\", \"State2\", \"67890\")\n",
    "], [\"house_number\", \"street\", \"city\", \"state\", \"zip_code\"])\n",
    "\n",
    "# Concatenate multiple columns into a full address\n",
    "df_address.select(concat(\n",
    "    df_address.house_number, lit(\" \"),\n",
    "    df_address.street, lit(\", \"),\n",
    "    df_address.city, lit(\", \"),\n",
    "    df_address.state, lit(\" \"),\n",
    "    df_address.zip_code\n",
    ").alias(\"full_address\")).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4588678-cf67-4648-858c-7cf4c78cb4d1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4. Concatenating Columns with Null Values\n",
    "\n",
    "**Scenario**: You have some columns with null values, and you want to concatenate them without resulting in null output.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f836fc0-78af-42bb-a6fd-6a75f834a95a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n|full_name|\n+---------+\n|    John |\n|    Smith|\n|Tom Brown|\n+---------+\n\n"
     ]
    }
   ],
   "source": [
    "df_with_nulls = spark.createDataFrame([\n",
    "    (\"John\", None),\n",
    "    (None, \"Smith\"),\n",
    "    (\"Tom\", \"Brown\")\n",
    "], [\"first_name\", \"last_name\"])\n",
    "\n",
    "# Concatenate columns with null values using coalesce to handle nulls\n",
    "from pyspark.sql.functions import coalesce\n",
    "\n",
    "df_with_nulls.select(concat(\n",
    "    coalesce(df_with_nulls.first_name, lit(\"\")),\n",
    "    lit(\" \"),\n",
    "    coalesce(df_with_nulls.last_name, lit(\"\"))\n",
    ").alias(\"full_name\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13e17c92-00e9-4b5f-a106-cc99188bb069",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5. Concatenating Columns and Literals\n",
    "\n",
    "**Scenario**: You want to concatenate columns with literal strings for formatting, such as creating a formatted full address.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0eadec0-dfc1-4baf-b5c4-a17b221efab8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------+\n|formatted_address                          |\n+-------------------------------------------+\n|Address: 123, Main St, City, State 12345   |\n|Address: 456, Broadway, City2, State2 67890|\n+-------------------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Concatenate columns with literal strings for formatting\n",
    "df_address.select(concat(\n",
    "    lit(\"Address: \"), df_address.house_number, lit(\", \"),\n",
    "    df_address.street, lit(\", \"),\n",
    "    df_address.city, lit(\", \"),\n",
    "    df_address.state, lit(\" \"),\n",
    "    df_address.zip_code\n",
    ").alias(\"formatted_address\")).show(truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "18_pyspark_concat_function_concatenating_columns",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
