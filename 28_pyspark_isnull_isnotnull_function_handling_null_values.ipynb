{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94be3061-e5ff-4f7a-8ac8-202cfbd66121",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## PySpark SQL isNull() and isNotNull() Functions: Handling Null Values in Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "203d9d98-c9c3-4ffc-8308-471a7897cfa1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Introduction to `isNull()` and `isNotNull()` Functions\n",
    "\n",
    "The `isNull()` and `isNotNull()` functions in PySpark are used to check if a column's value is null or not null, respectively. Null values in datasets can represent missing or undefined data, and handling them properly is crucial in data analysis and transformations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99c192af-104c-498f-b823-929c31795517",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Basic Syntax:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7ff058e-e4f2-49cf-be77-4f8f171caed2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "```\n",
    "DataFrame.filter(column.isNull())\n",
    "DataFrame.filter(column.isNotNull())\n",
    "```\n",
    "\n",
    "### Functions:\n",
    "\n",
    "- **`isNull()`**: Returns rows where the column has a null value.\n",
    "- **`isNotNull()`**: Returns rows where the column is not null.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "982a1e84-dffa-4048-9d91-05b7aa9670b4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Why Use `isNull()` and `isNotNull()`?\n",
    "\n",
    "- Null values often indicate missing data that needs special treatment, whether through filtering, filling missing values, or applying specific rules.\n",
    "- `isNull()` and `isNotNull()` help identify and manage such null values in your dataset, allowing you to handle missing or undefined data appropriately during analysis and transformations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "173fa533-9b0d-4594-8864-ed09ad231093",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Practical Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8894714b-0359-4f31-be60-aeaabe5be1b4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1. Filtering Rows with Null Values\n",
    "\n",
    "**Scenario**: You have a DataFrame with product sales, and some sales values are null. You want to filter rows where sales are null.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4aad800f-bb77-40aa-a320-61bb9073dde1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n|product_name|sales|\n+------------+-----+\n|   Product B| null|\n+------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([\n",
    "    (\"Product A\", 500),\n",
    "    (\"Product B\", None),\n",
    "    (\"Product C\", 700)\n",
    "], [\"product_name\", \"sales\"])\n",
    "\n",
    "# Filter rows where sales are null\n",
    "df.filter(df.sales.isNull()).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3203ce8-6ffb-4683-a6dc-35da1fb83deb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2. Filtering Rows with Non-Null Values\n",
    "\n",
    "**Scenario**: You want to filter out rows where the sales value is null, keeping only rows with valid sales values.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffddedb2-dd85-4704-a2c1-b0552b0d16dc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n|product_name|sales|\n+------------+-----+\n|   Product A|  500|\n|   Product C|  700|\n+------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where sales are not null\n",
    "df.filter(df.sales.isNotNull()).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6753bd4d-4c24-49a7-a5a2-708a321f4a5f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3. Using `isNull()` for Data Cleaning\n",
    "\n",
    "**Scenario**: You want to clean your data by replacing null values in the sales column with a default value, such as 0.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60eba014-bc77-4730-bd91-8e52ba9f1405",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n|product_name|sales|\n+------------+-----+\n|   Product A|  500|\n|   Product B|    0|\n|   Product C|  700|\n+------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Replace null sales with 0\n",
    "df_cleaned = df.withColumn(\"sales\", when(df.sales.isNull(), 0).otherwise(df.sales))\n",
    "df_cleaned.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b9ac6d7-a55b-4bf4-a65e-66c9240e0e22",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4. Combining `isNull()` and `isNotNull()` with Other Filters\n",
    "\n",
    "**Scenario**: You want to filter rows where the sales are greater than 400 and not null.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92be537c-8c12-41ae-a53a-05a83b4fb367",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n|product_name|sales|\n+------------+-----+\n|   Product A|  500|\n|   Product C|  700|\n+------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where sales are greater than 400 and not null\n",
    "df.filter(df.sales.isNotNull() & (df.sales > 400)).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08dd58f7-3069-431b-b173-e7daec55ec8e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5. Counting Null and Non-Null Values in a Column\n",
    "\n",
    "**Scenario**: You want to count how many rows have null values in the sales column and how many are not null.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c2ad24c-5f24-4efd-9f5b-57ab6379aab2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null sales count: 1\nNon-null sales count: 2\n"
     ]
    }
   ],
   "source": [
    "# Count rows with null and non-null sales\n",
    "null_count = df.filter(df.sales.isNull()).count()\n",
    "not_null_count = df.filter(df.sales.isNotNull()).count()\n",
    "\n",
    "print(f\"Null sales count: {null_count}\")\n",
    "print(f\"Non-null sales count: {not_null_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "401a3b26-a3ab-4006-bd98-69d234592187",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 6. Using `isNull()` and `isNotNull()` with Multiple Columns\n",
    "\n",
    "**Scenario**: You have a DataFrame with multiple columns, and you want to filter rows where both the `Sales` and `ProductName` columns are not null.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d44c76b8-c138-469d-9ce5-8f07aa5ea1af",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n|product_name|sales|\n+------------+-----+\n|   Product A|  500|\n|   Product C|  700|\n+------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where both product_name and sales are not null\n",
    "df.filter(df.product_name.isNotNull() & df.sales.isNotNull()).show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "28_pyspark_isnull_isnotnull_function_handling_null_values",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
