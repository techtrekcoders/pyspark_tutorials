{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ac9cadb-06f3-400d-85b8-031cede5a4dc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# PySpark SQL sum() Function: Summing Values Made Simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ecdf96bf-9e28-4542-b987-7e096ca05222",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Introduction to the `sum()` Function\n",
    "\n",
    "The `sum()` function in PySpark is used to calculate the sum of numeric values across one or more columns. It works similarly to the SQL `SUM()` function and is a common aggregation operation when working with large datasets, especially in financial or transactional data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6af9bd70-85be-459e-8e43-e43251551639",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Basic Syntax:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5705a99f-aefa-4025-827d-7e1be38ad719",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "```\n",
    "DataFrame.groupBy(*cols).agg(sum(\"columnName\"))\n",
    "```\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "- **`cols`**: The column(s) to group by (if needed).\n",
    "- **`sum(\"columnName\")`**: Applies the summing operation to the specified column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6bd34ee4-279b-4079-8971-aeb61390dc1c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Why Use `sum()`?\n",
    "\n",
    "- It is essential for computing total values, such as sales, profits, expenses, or any numeric metric that needs to be aggregated.\n",
    "- It can be used in combination with `groupBy()` for grouped sums, or it can calculate global sums across the entire DataFrame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3677cbb-6f35-4c8e-99f4-fb2d5f8a7793",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Practical Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74ae04db-21fb-46a2-9ad0-b321f68c4c28",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1. Summing a Single Column\n",
    "\n",
    "**Scenario**: You have a DataFrame with sales data, and you want to calculate the total sales.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae25bf15-a6cc-4d63-91a5-9122dcad1d50",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n|TOTAL_SALES|\n+-----------+\n|       1500|\n+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "\n",
    "df = spark.createDataFrame([\n",
    "    (\"ItemA\", 100),\n",
    "    (\"ItemB\", 200),\n",
    "    (\"ItemA\", 300),\n",
    "    (\"ItemC\", 400),\n",
    "    (\"ItemB\", 500)\n",
    "], [\"ITEM\", \"SALES\"])\n",
    "\n",
    "# Sum the SALES column\n",
    "df.agg(sum(\"SALES\").alias(\"TOTAL_SALES\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1cef865a-cfc1-4973-ba56-6b2ec21d03e0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2. Grouping and Summing Values\n",
    "\n",
    "**Scenario**: You want to group by `ITEM` and calculate the total sales for each item.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82217137-a59c-4c0b-a66b-64502c836321",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+\n| ITEM|TOTAL_SALES|\n+-----+-----------+\n|ItemA|        400|\n|ItemB|        700|\n|ItemC|        400|\n+-----+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Group by ITEM and sum SALES for each group\n",
    "df.groupBy(\"ITEM\").agg(sum(\"SALES\").alias(\"TOTAL_SALES\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8fdf6847-01d7-4e08-b6a4-9be09de3aeb1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3. Summing Multiple Columns\n",
    "\n",
    "**Scenario**: You have sales and profit data, and you want to sum both columns.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ab80dd7-4b3e-4913-a4cc-ffc71123ad31",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+\n|TOTAL_SALES|TOTAL_PROFIT|\n+-----------+------------+\n|       1500|         150|\n+-----------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "df_multi = spark.createDataFrame([\n",
    "    (\"ItemA\", 100, 10),\n",
    "    (\"ItemB\", 200, 20),\n",
    "    (\"ItemA\", 300, 30),\n",
    "    (\"ItemC\", 400, 40),\n",
    "    (\"ItemB\", 500, 50)\n",
    "], [\"ITEM\", \"SALES\", \"PROFIT\"])\n",
    "\n",
    "# Sum SALES and PROFIT for the entire DataFrame\n",
    "df_multi.agg(\n",
    "    sum(\"SALES\").alias(\"TOTAL_SALES\"),\n",
    "    sum(\"PROFIT\").alias(\"TOTAL_PROFIT\")\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc2ae72c-39f1-4601-aa74-fea5d2c91971",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4. Summing with a Conditional Expression\n",
    "\n",
    "**Scenario**: You want to sum the sales where the sales value is greater than $200.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39648b48-c1ad-40bb-9d5e-5b06aa4ff1d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n|TOTAL_SALES_OVER_200|\n+--------------------+\n|                1200|\n+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Sum SALES where SALES > 200\n",
    "df.agg(sum(when(df.SALES > 200, df.SALES)).alias(\"TOTAL_SALES_OVER_200\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "35c59576-7074-43c3-8163-244d24e77a98",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5. Summing Without Grouping (Global Aggregation)\n",
    "\n",
    "**Scenario**: You want to calculate the total sales across the entire dataset, without any grouping.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "973aae44-12c2-4970-a58a-978b6688c6f9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n|TOTAL_GLOBAL_SALES|\n+------------------+\n|              1500|\n+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Global sum of SALES without grouping\n",
    "df.agg(sum(\"SALES\").alias(\"TOTAL_GLOBAL_SALES\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f1302c6-664a-4132-aa77-f7514ef11d48",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 6. Summing Multiple Aggregations in `agg()`\n",
    "\n",
    "**Scenario**: You want to calculate the total sales and the total number of transactions (i.e., count of rows) for each item.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc3c7e1d-26c1-4a90-91a4-b6f5bfef6279",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+------------------+\n| ITEM|TOTAL_SALES|TOTAL_TRANSACTIONS|\n+-----+-----------+------------------+\n|ItemA|        400|                 2|\n|ItemB|        700|                 2|\n|ItemC|        400|                 1|\n+-----+-----------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "\n",
    "# Group by ITEM, sum SALES, and count transactions\n",
    "df.groupBy(\"ITEM\").agg(\n",
    "    sum(\"SALES\").alias(\"TOTAL_SALES\"),\n",
    "    count(\"*\").alias(\"TOTAL_TRANSACTIONS\")\n",
    ").show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "10_pyspark_sum_function_summing_values_made_simple",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
