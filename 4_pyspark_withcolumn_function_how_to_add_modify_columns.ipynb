{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f516ca1b-d35c-47df-b472-35f451f5eed5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# PySpark SQL withColumn() Function: How to Add or Modify Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "510e7d58-0d47-437e-8100-5bc806102504",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Introduction to the `withColumn()` Function\n",
    "\n",
    "The `withColumn()` function in PySpark is used to create a new column or modify an existing column in a DataFrame. It allows you to apply transformations to existing columns or introduce completely new ones based on some logic or calculation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d845f3b-3da4-4cba-9be1-dd135c4df15e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Basic Syntax:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc07517f-152a-4a6e-87f6-af7ed4b9310f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "```\n",
    "DataFrame.withColumn(columnName, expression)\n",
    "```\n",
    "\n",
    "#### Parameters\n",
    "\n",
    "- **`columnName`**: The name of the new or existing column that you want to create or modify.\n",
    "- **`expression`**: The transformation or calculation to be applied to create or modify the column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "efe70c9a-4678-4338-b9a1-56dcdee34580",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## How It Works:\n",
    "\n",
    "- If the specified column already exists, `withColumn()` will overwrite it.\n",
    "- If the column does not exist, a new column will be created.\n",
    "- It’s a powerful function for data transformation and preparing data for further analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31267935-c89c-4707-88ca-9aa9243f2fdb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Practical Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80fecc1e-e255-4e35-9725-61f3e5ab2743",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1. Adding a New Column with a Simple Expression\n",
    "\n",
    "**Scenario**: You have a DataFrame with employee salary data, and you want to add a new column that increases each employee’s salary by 10%.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5927fa60-bebd-4b79-a35b-d5eeb70f87fe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+------+------------------+\n|EMPLOYEE_ID|NAME|SALARY|        NEW_SALARY|\n+-----------+----+------+------------------+\n|          1|John|  3000|3300.0000000000005|\n|          2|Jane|  4000|            4400.0|\n|          3| Tom|  3500|3850.0000000000005|\n+-----------+----+------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([\n",
    "    (1, \"John\", 3000),\n",
    "    (2, \"Jane\", 4000),\n",
    "    (3, \"Tom\", 3500)\n",
    "], [\"EMPLOYEE_ID\", \"NAME\", \"SALARY\"])\n",
    "\n",
    "# Add new column \"NEW_SALARY\" with 10% salary increase\n",
    "df.withColumn(\"NEW_SALARY\", df.SALARY * 1.1).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3cde521e-e27b-482e-990d-1176becf57b7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2. Modifying an Existing Column\n",
    "\n",
    "**Scenario**: You want to modify the `Salary` column itself by applying a 10% increase, instead of adding a new column.\n",
    "\n",
    "**Code Example**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "497e2592-18b9-4544-9dfb-8d8794bf2aa1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+------------------+\n|EMPLOYEE_ID|NAME|            SALARY|\n+-----------+----+------------------+\n|          1|John|3300.0000000000005|\n|          2|Jane|            4400.0|\n|          3| Tom|3850.0000000000005|\n+-----------+----+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Modify the existing \"SALARY\" column by increasing it by 10%\n",
    "df.withColumn(\"SALARY\", df.SALARY * 1.1).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02382700-d016-4e8f-9d80-b330dbc17573",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3. Adding a Column Based on a Conditional Expression\n",
    "\n",
    "**Scenario**: You want to add a new column `BONUS_ELIGIBLE` that assigns `True` if an employee’s salary is greater than $3,500, and `False` otherwise.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84b4743d-4a56-42b3-8d3e-2a4103de67d0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+------+--------------+\n|EMPLOYEE_ID|NAME|SALARY|BONUS_ELIGIBLE|\n+-----------+----+------+--------------+\n|          1|John|  3000|         false|\n|          2|Jane|  4000|          true|\n|          3| Tom|  3500|         false|\n+-----------+----+------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Add new column \"BONUS_ELIGIBLE\" based on condition\n",
    "df.withColumn(\"BONUS_ELIGIBLE\", when(df.SALARY > 3500, True).otherwise(False)).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b227b94-6281-46a2-9966-7fc126e881dc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4. Using `withColumn()` to Create a Column Based on Multiple Columns\n",
    "\n",
    "**Scenario**: You want to add a new column `TOTAL_COMPENSATION` which sums up both `Salary` and `Bonus` columns.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cec878c2-0c75-449d-9969-64d890c7cd9c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+------+-----+------------------+\n|EMPLOYEE_ID|NAME|SALARY|BONUS|TOTAL_COMPENSATION|\n+-----------+----+------+-----+------------------+\n|          1|John|  3000|  500|              3500|\n|          2|Jane|  4000|  800|              4800|\n|          3| Tom|  3500|  600|              4100|\n+-----------+----+------+-----+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df_bonus = spark.createDataFrame([\n",
    "    (1, \"John\", 3000, 500),\n",
    "    (2, \"Jane\", 4000, 800),\n",
    "    (3, \"Tom\", 3500, 600)\n",
    "], [\"EMPLOYEE_ID\", \"NAME\", \"SALARY\", \"BONUS\"])\n",
    "\n",
    "# Add a new column \"TOTAL_COMPENSATION\" as the sum of SALARY and BONUS\n",
    "df_bonus.withColumn(\"TOTAL_COMPENSATION\", df_bonus.SALARY + df_bonus.BONUS).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16cdb8e2-8cfc-4373-9cd8-c40515e257e8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5. Using Built-in Functions in `withColumn()`\n",
    "\n",
    "**Scenario**: You want to add a column that contains the length of each employee’s name.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a73437a-b88c-4d44-b48a-bc47074807ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+------+-----------+\n|EMPLOYEE_ID|NAME|SALARY|NAME_LENGTH|\n+-----------+----+------+-----------+\n|          1|John|  3000|          4|\n|          2|Jane|  4000|          4|\n|          3| Tom|  3500|          3|\n+-----------+----+------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import length\n",
    "\n",
    "# Add new column \"NAME_LENGTH\" using length function\n",
    "df.withColumn(\"NAME_LENGTH\", length(df.NAME)).show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4_pyspark_withcolumn_function_how_to_add_modify_columns",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
