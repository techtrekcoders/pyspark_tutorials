{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee49b82f-7c3e-4e5f-b0cf-89e93ab55533",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## PySpark SQL lower() and upper() Functions: Changing String Case Made Easy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8b55dc8-ba95-4747-a7c5-d1c8ee09e9ed",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Introduction to `lower()` and `upper()` Functions\n",
    "\n",
    "The `lower()` and `upper()` functions in PySpark are used to convert string columns to lowercase and uppercase, respectively. These functions are useful for standardizing text data, especially when performing comparisons, searches, or cleaning inconsistent case formatting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08a7f034-a84e-4116-9cc8-46eb33f0d378",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Basic Syntax:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d79758f-3b7d-4387-8c24-793fc43dca3a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "```\n",
    "from pyspark.sql.functions import lower, upper\n",
    "\n",
    "DataFrame.select(lower(column).alias(\"lowercase_column\"))\n",
    "DataFrame.select(upper(column).alias(\"uppercase_column\"))\n",
    "```\n",
    "\n",
    "### Functions:\n",
    "\n",
    "- **`lower()`**: Converts the string to lowercase.\n",
    "- **`upper()`**: Converts the string to uppercase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e537556d-ef58-4add-b1ba-078a978a30db",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Why Use `lower()` and `upper()`?\n",
    "\n",
    "- These functions are helpful for making text comparisons case-insensitive, standardizing case across datasets, or preparing text data for display.\n",
    "- They are often used in data cleaning processes to handle inconsistent capitalization in names, addresses, product descriptions, and other text fields.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f504b9e7-90ac-4e60-8055-5e5237b239b7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Practical Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff00a603-8341-475f-b312-c065df55a678",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1. Converting a Column to Lowercase\n",
    "\n",
    "**Scenario**: You have a DataFrame with product names in mixed case, and you want to convert all product names to lowercase.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99024fe3-db32-4aaa-b4d6-78a507003476",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n|lowercase_product_name|\n+----------------------+\n|             product a|\n|             product b|\n|             product c|\n+----------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lower, upper\n",
    "\n",
    "df = spark.createDataFrame([\n",
    "    (\"Product A\",),\n",
    "    (\"Product B\",),\n",
    "    (\"Product C\",)\n",
    "], [\"product_name\"])\n",
    "\n",
    "# Convert product_name to lowercase\n",
    "df.select(lower(df.product_name).alias(\"lowercase_product_name\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a719f6e8-d6ea-4432-b8a0-6eeaf9e77e21",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2. Converting a Column to Uppercase\n",
    "\n",
    "**Scenario**: You want to convert product names to uppercase for display purposes.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa500dc4-fe5a-4a14-8da0-6f83180ae34f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n|uppercase_product_name|\n+----------------------+\n|             PRODUCT A|\n|             PRODUCT B|\n|             PRODUCT C|\n+----------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Convert product_name to uppercase\n",
    "df.select(upper(df.product_name).alias(\"uppercase_product_name\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2eb493f0-9ce2-45af-9bee-40bc6f692a3e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3. Combining `lower()` and `upper()` with Other Functions\n",
    "\n",
    "**Scenario**: You want to concatenate first and last names and then convert the result to either lowercase or uppercase.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7ee27ba-1078-4710-a44b-dd90af828b22",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n|lowercase_full_name|\n+-------------------+\n|           john doe|\n|         jane smith|\n|          tom brown|\n+-------------------+\n\n+-------------------+\n|uppercase_full_name|\n+-------------------+\n|           JOHN DOE|\n|         JANE SMITH|\n|          TOM BROWN|\n+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat, lit\n",
    "\n",
    "df_names = spark.createDataFrame([\n",
    "    (\"John\", \"Doe\"),\n",
    "    (\"Jane\", \"Smith\"),\n",
    "    (\"Tom\", \"Brown\")\n",
    "], [\"first_name\", \"last_name\"])\n",
    "\n",
    "# Concatenate first_name and last_name and convert to lowercase\n",
    "df_names.select(\n",
    "    lower(concat(df_names.first_name, lit(\" \"), df_names.last_name)).alias(\"lowercase_full_name\")\n",
    ").show()\n",
    "\n",
    "# Concatenate first_name and last_name and convert to uppercase\n",
    "df_names.select(\n",
    "    upper(concat(df_names.first_name, lit(\" \"), df_names.last_name)).alias(\"uppercase_full_name\")\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f5c68c8-6d6a-48a1-a1a5-fa343bc337c3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4. Using `lower()` and `upper()` for Case-Insensitive Matching\n",
    "\n",
    "**Scenario**: You want to make a case-insensitive comparison, such as filtering rows where the product name is \"product a\" regardless of its case.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f33920f2-c67a-4779-a82c-487b4ce11ab1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n|product_name|\n+------------+\n|   Product A|\n+------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where product_name is 'product a', ignoring case\n",
    "df.filter(lower(df.product_name) == \"product a\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42d16fff-98e9-4595-aa02-c32177dc4a86",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5. Handling Null Values in `lower()` and `upper()`\n",
    "\n",
    "**Scenario**: You want to ensure that null values in a column donâ€™t cause issues when converting case.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4acb1ca-d302-4f5b-bf4d-2563c3e8fbd1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n|lowercase_name|\n+--------------+\n|          john|\n|          null|\n|           tom|\n+--------------+\n\n+--------------+\n|uppercase_name|\n+--------------+\n|          JOHN|\n|          null|\n|           TOM|\n+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "df_with_nulls = spark.createDataFrame([\n",
    "    (\"John\",),\n",
    "    (None,),\n",
    "    (\"Tom\",)\n",
    "], [\"name\"])\n",
    "\n",
    "# Convert to lowercase and handle null values\n",
    "df_with_nulls.select(lower(df_with_nulls.name).alias(\"lowercase_name\")).show()\n",
    "\n",
    "# Convert to uppercase and handle null values\n",
    "df_with_nulls.select(upper(df_with_nulls.name).alias(\"uppercase_name\")).show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "23_pyspark_lower_upper_function_changing_string_case",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
