{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48d446e8-13a6-427e-8af8-7d1f35186e2c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# PySpark SQL select() Function: How to Select Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9d7d0e8-40eb-4950-9a9a-236ccb930b56",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## What is the `select()` Function?\n",
    "\n",
    "The `select()` function in PySpark is used to select one or more columns from a DataFrame. \n",
    "\n",
    "It allows you to:\n",
    "- Pick specific columns\n",
    "- Rename columns\n",
    "- Apply transformations or expressions\n",
    "\n",
    "Itâ€™s similar to the `SELECT` statement in SQL, where you specify which columns you want to retrieve from a table.\n",
    "\n",
    "In PySpark, `select()` is one of the most commonly used functions when working with DataFrames, especially when you want to filter out unnecessary columns or transform data in specific columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88d5bbe5-f281-4b58-b519-6b1704b0a3e1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Syntax:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3c53ca2-2f38-4fcf-8d70-d5463e897317",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "```\n",
    "DataFrame.select(*cols)\n",
    "```\n",
    "\n",
    "cols: The columns you want to select from the DataFrame. These can be specified as strings (column names) or as expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96ad6149-4047-4e28-b4ee-c10a5a45b3fe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Key Features of `select()` Function\n",
    "\n",
    "- **Selecting specific columns**:  \n",
    "  You can pass column names directly to the `select()` function to retrieve the columns you need.\n",
    "\n",
    "- **Column renaming**:  \n",
    "  You can rename columns using the `alias()` method.\n",
    "\n",
    "- **Expressions**:  \n",
    "  You can apply expressions to columns, such as adding, multiplying, or creating new calculated columns.\n",
    "\n",
    "- **Selecting nested columns**:  \n",
    "  If your DataFrame contains nested data, `select()` allows you to extract specific fields from those nested structures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "177d00e4-ad51-42a7-a1d2-10f2b29f22b4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Practical Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a775d67-e00f-4cea-8dd1-d08ffeb4aaa8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Example 1: Basic Column Selection\n",
    "\n",
    "You have a DataFrame containing employee data, and you only want to view specific columns like `EMPLOYEE_ID` and `FIRST_NAME`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9553c714-306a-4ba7-8405-df60d673751a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n|EMPLOYEE_ID|FIRST_NAME|\n+-----------+----------+\n|          1|      John|\n|          2|      Jane|\n|          3|       Tom|\n+-----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Sample DataFrame\n",
    "df = spark.createDataFrame([\n",
    "    (1, \"John\", \"Smith\", 3000),\n",
    "    (2, \"Jane\", \"Doe\", 4000),\n",
    "    (3, \"Tom\", \"Hardy\", 3500)\n",
    "], [\"EMPLOYEE_ID\", \"FIRST_NAME\", \"LAST_NAME\", \"SALARY\"])\n",
    "\n",
    "# Select specific columns\n",
    "df.select(\"EMPLOYEE_ID\", \"FIRST_NAME\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81b96899-e137-4582-83fe-75d52f097a94",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Example 2: Selecting Columns with Aliases\n",
    "\n",
    "You want to display `FIRST_NAME` and `SALARY`, but rename `SALARY` to `EMPLOYEE_SALARY`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abf8a690-019c-4e7b-a894-265b435ab595",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n|FIRST_NAME|EMPLOYEE_SALARY|\n+----------+---------------+\n|      John|           3000|\n|      Jane|           4000|\n|       Tom|           3500|\n+----------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Select columns and rename using alias\n",
    "df.select(\"FIRST_NAME\", col(\"SALARY\").alias(\"EMPLOYEE_SALARY\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf12f5c2-7dd7-4dbc-a10a-42665f782197",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Example 3: Applying Expressions in `select()`\n",
    "\n",
    "You want to show the `FIRST_NAME` and `LAST_NAME` along with a new column that calculates a 10% increase in the `SALARY`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54912414-4fe0-42b3-a146-422923a657c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------+\n|FIRST_NAME|LAST_NAME|NEW_SALARY|\n+----------+---------+----------+\n|      John|    Smith|    3300.0|\n|      Jane|      Doe|    4400.0|\n|       Tom|    Hardy|    3850.0|\n+----------+---------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "# Select columns and apply expression\n",
    "df.select(\"FIRST_NAME\", \"LAST_NAME\", expr(\"SALARY * 1.1\").alias(\"NEW_SALARY\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce7ef8e1-fd72-4eba-b163-2071d5aa8d49",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Example 4: Selecting Nested Columns\n",
    "\n",
    "You have a DataFrame with nested columns and want to extract specific fields from the nested structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3f179e6-14d7-498c-a09c-2bbe7bcaa459",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n|NAME|   city|\n+----+-------+\n|John| Denver|\n|Jane|Seattle|\n+----+-------+\n\n"
     ]
    }
   ],
   "source": [
    "# Sample nested DataFrame\n",
    "data = [\n",
    "    (1, \"John\", {\"street\": \"1234 Elm St\", \"city\": \"Denver\"}),\n",
    "    (2, \"Jane\", {\"street\": \"5678 Maple St\", \"city\": \"Seattle\"})\n",
    "]\n",
    "df_nested = spark.createDataFrame(data, [\"EMPLOYEE_ID\", \"NAME\", \"ADDRESS\"])\n",
    "\n",
    "# Select fields from nested columns\n",
    "df_nested.select(\"NAME\", \"ADDRESS.city\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da8a7753-637f-4b21-8a1f-66fd4533194e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Example 5: Using `selectExpr()` for SQL-like Expressions\n",
    "\n",
    "You want to use SQL-like expressions within `select()`. This can be achieved using `selectExpr()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0640a4a-bae0-4bcd-b677-2f98829718f6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n|FIRST_NAME|DOUBLE_SALARY|\n+----------+-------------+\n|      John|         6000|\n|      Jane|         8000|\n|       Tom|         7000|\n+----------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Using selectExpr for SQL-like expressions\n",
    "df.selectExpr(\"FIRST_NAME\", \"SALARY * 2 as DOUBLE_SALARY\").show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1_pyspark_select_function_how_to_select_columns",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
