{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "007ff1a1-fbfb-41ef-a1ca-6f4d875af754",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# PySpark SQL alias() Function: How to Rename Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "58020544-2922-4ddc-acd2-6dd8d1273352",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Introduction to the `alias()` Function\n",
    "\n",
    "The `alias()` function in PySpark allows you to assign a temporary name (alias) to a column. It’s commonly used when you need to rename columns during transformations or when performing operations like `select()`, `groupBy()`, or `withColumn()`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3706ac6a-cc81-4c5c-8b2f-5c7ac7b1a14d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Basic Syntax:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "258b731f-eab7-43dd-93cb-7bc9be944a9e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "```\n",
    "column.alias(newName)\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- **`newName`**: The new alias for the column. This name is temporary and only applies to the current DataFrame operation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25903c19-d876-481f-9021-ec13b19bb8f3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Why Use `alias()`?\n",
    "\n",
    "- It makes columns easier to reference in complex queries.\n",
    "- It’s useful when you need a more meaningful or shorter name for columns in the result set.\n",
    "- It’s often used when performing aggregation, joins, or other operations where column names might be ambiguous or need clarity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a963bbda-53ad-4702-aca8-9ccda0217116",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Practical Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb970145-a63a-463b-8d9f-6c6fb47ff7f7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1. Renaming a Single Column\n",
    "\n",
    "**Scenario**: You have a DataFrame with employee data, and you want to rename the `Salary` column to `Employee_Salary` in the result set.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b651f57-c410-44b5-b55b-2a22c837389c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+---------------+\n|EMPLOYEE_ID|NAME|EMPLOYEE_SALARY|\n+-----------+----+---------------+\n|          1|John|           3000|\n|          2|Jane|           4000|\n|          3| Tom|           3500|\n+-----------+----+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([\n",
    "    (1, \"John\", 3000),\n",
    "    (2, \"Jane\", 4000),\n",
    "    (3, \"Tom\", 3500)\n",
    "], [\"EMPLOYEE_ID\", \"NAME\", \"SALARY\"])\n",
    "\n",
    "# Rename the \"SALARY\" column to \"EMPLOYEE_SALARY\"\n",
    "df.select(\"EMPLOYEE_ID\", \"NAME\", df.SALARY.alias(\"EMPLOYEE_SALARY\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ccdd6bd-c5a3-424e-99ce-b28a01bd6790",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2. Renaming Multiple Columns\n",
    "\n",
    "**Scenario**: You want to rename both the `Employee` column to `ID` and the `Salary` column to `Emp_Salary` using `alias()`.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d484932-1e6e-4ff4-b84b-66bfa2d518b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----------+\n| ID|NAME|EMP_SALARY|\n+---+----+----------+\n|  1|John|      3000|\n|  2|Jane|      4000|\n|  3| Tom|      3500|\n+---+----+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Rename multiple columns using alias\n",
    "df.select(df.EMPLOYEE_ID.alias(\"ID\"), \"NAME\", df.SALARY.alias(\"EMP_SALARY\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d9ec46b-e923-4795-b990-36a56f34a8cb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3. Using `alias()` with Expressions\n",
    "\n",
    "**Scenario**: You want to create a new column by calculating a 10% increase in the `Salary` and rename it as `Increased_Salary`.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5abd4fb-8117-40e0-ac6f-38884166bad2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+------------------+\n|EMPLOYEE_ID|NAME|  INCREASED_SALARY|\n+-----------+----+------------------+\n|          1|John|3300.0000000000005|\n|          2|Jane|            4400.0|\n|          3| Tom|3850.0000000000005|\n+-----------+----+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Using alias with an expression\n",
    "df.select(\"EMPLOYEE_ID\", \"NAME\", (df.SALARY * 1.1).alias(\"INCREASED_SALARY\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c805c82e-0a45-462e-8d8e-f02d34a06f17",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4. Using `alias()` in Aggregations\n",
    "\n",
    "**Scenario**: You want to calculate the total salary for all employees and rename the result as `Total_Salary`.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "373c6e98-5828-4d44-9418-9f2d3459d9cb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n|TOTAL_SALARY|\n+------------+\n|       10500|\n+------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "\n",
    "# Using alias in aggregation\n",
    "df.select(sum(\"SALARY\").alias(\"TOTAL_SALARY\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ac08ce5-5dcd-4599-abf6-084541653135",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5. Using `alias()` with Grouping\n",
    "\n",
    "**Scenario**: You want to group employees by name and calculate their total salary, renaming the result as `Total_Salary_Per_Name`.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35cb7023-24ec-4f2d-87b0-82b178ac852c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------+\n|NAME|TOTAL_SALARY_PER_NAME|\n+----+---------------------+\n|John|                 3000|\n|Jane|                 4000|\n| Tom|                 3500|\n+----+---------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Using alias with groupBy and aggregation\n",
    "df.groupBy(\"NAME\").agg(sum(\"SALARY\").alias(\"TOTAL_SALARY_PER_NAME\")).show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "6_pyspark_alias_function_how_to_rename_columns",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
