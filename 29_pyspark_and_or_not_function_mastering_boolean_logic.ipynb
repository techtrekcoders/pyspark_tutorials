{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8d65073-be48-4334-8d98-a045cfc5c58e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# PySpark SQL and(), or(), not() Functions: Mastering Boolean Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3842c648-380c-438c-80c6-9ce06febd842",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Introduction to Boolean Logic with `and()`, `or()`, and `not()`\n",
    "\n",
    "The `and()`, `or()`, and `not()` functions in PySpark are used to apply Boolean logic to DataFrame filtering and conditional expressions. These functions allow you to combine multiple conditions (`and()` and `or()`), or negate a condition (`not()`). These are commonly used in data filtering, where multiple criteria need to be satisfied, or specific conditions should be excluded.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7746f0c3-0d7a-49e5-82cb-c792f4672752",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Basic Syntax:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69944206-086a-4f5e-b32a-b96bb57c0148",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "```\n",
    "DataFrame.filter((condition1).and(condition2))\n",
    "DataFrame.filter((condition1).or(condition2))\n",
    "DataFrame.filter(not(condition))\n",
    "```\n",
    "\n",
    "### Functions:\n",
    "\n",
    "- **`and()`**: Returns true if both conditions are true.\n",
    "- **`or()`**: Returns true if at least one condition is true.\n",
    "- **`not()`**: Returns true if the condition is false.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ef69b65-7f3d-419c-86d9-c17e1b64b72e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Why Use Boolean Logic?\n",
    "\n",
    "These functions allow for powerful filtering and conditional logic by combining multiple expressions. This is especially useful in complex data queries where multiple conditions need to be evaluated simultaneously, making data filtering more flexible and precise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1da8b78-83ef-47a6-b822-c0f57acb45a0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Practical Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9054564-6e28-4e64-8a66-add1f88f925b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1. Using `and()` for Combining Conditions\n",
    "\n",
    "**Scenario**: You have a DataFrame with sales data, and you want to filter rows where sales are greater than 300 and less than 600.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14782d7f-94c0-4b0d-88c1-109b84fcdeb3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n|product_name|sales|\n+------------+-----+\n|   Product A|  500|\n+------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([\n",
    "    (\"Product A\", 500),\n",
    "    (\"Product B\", 300),\n",
    "    (\"Product C\", 700)\n",
    "], [\"product_name\", \"sales\"])\n",
    "\n",
    "# Use and() to filter rows where sales are between 300 and 600\n",
    "df.filter((df.sales > 300) & (df.sales < 600)).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c510b86-6ce1-4789-b5a8-b954775a08ee",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2. Using `or()` for Multiple Conditions\n",
    "\n",
    "**Scenario**: You want to filter rows where either the product name is \"Product A\" or the sales are greater than 600.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88d216a0-6fa7-4616-8ffb-550f220e8897",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n|product_name|sales|\n+------------+-----+\n|   Product A|  500|\n|   Product C|  700|\n+------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Use or() to filter rows where product_name is 'Product A' or sales > 600\n",
    "df.filter((df.product_name == \"Product A\") | (df.sales > 600)).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a18295ee-7227-4ff3-8085-ea36ac9f22eb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3. Using `not()` to Negate Conditions\n",
    "\n",
    "**Scenario**: You want to filter rows where sales are not equal to 300.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88566319-ab91-41e8-a8c5-6dfb13bb626a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n|product_name|sales|\n+------------+-----+\n|   Product A|  500|\n|   Product C|  700|\n+------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Use not() to filter rows where sales are not equal to 300\n",
    "df.filter(~(df.sales == 300)).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38155fc7-349f-4d00-9d07-d6822bced565",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4. Combining `and()`, `or()`, and `not()` for Complex Filtering\n",
    "\n",
    "**Scenario**: You want to filter rows where the sales are either greater than 600 or less than 300, but you want to exclude any rows with product name \"Product C.\"\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41a27ac0-9ede-4598-a4c0-0ca46d13243d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n|product_name|sales|\n+------------+-----+\n+------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Combine and(), or(), and not() for complex filtering\n",
    "df.filter(((df.sales > 600)|(df.sales < 300)) & (~(df.product_name == \"Product C\"))).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cae37701-dcb1-4317-8c14-c1c5e3b0cd49",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5. Using `and()` and `or()` for String Columns\n",
    "\n",
    "**Scenario**: You want to filter rows where the product name starts with \"Product A\" and sales are greater than 400.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f53d780f-e72c-4fbf-8539-e73e193547a0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n|product_name|sales|\n+------------+-----+\n|   Product A|  500|\n+------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Use and() to combine conditions for string columns and numeric columns\n",
    "df.filter((df.product_name.startswith(\"Product A\")) & (df.sales > 400)).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f4d27a4-2127-475f-935d-5db571fb3cbd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 6. Using `or()` and `not()` with Null Values\n",
    "\n",
    "**Scenario**: You have a DataFrame with some null values, and you want to filter rows where either sales are null or the product name is not \"Product B.\"\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1b83707-8273-4dcb-9175-8a3f408f8ca3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n|product_name|sales|\n+------------+-----+\n|   Product A|  500|\n|   Product B| null|\n|   Product C|  700|\n+------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df_with_nulls = spark.createDataFrame([\n",
    "    (\"Product A\", 500),\n",
    "    (\"Product B\", None),\n",
    "    (\"Product C\", 700)\n",
    "], [\"product_name\", \"sales\"])\n",
    "\n",
    "# Use or() and not() with null values\n",
    "df_with_nulls.filter((df_with_nulls.sales.isNull()) | (~(df_with_nulls.product_name == \"Product B\"))).show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "29_pyspark_and_or_not_function_mastering_boolean_logic",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
