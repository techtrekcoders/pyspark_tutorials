{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c2ecfb1-bf64-4235-82be-8c0096f3272b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# PySpark SQL count() Function: How to Count Rows and Column Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01f1cbc0-f72e-4129-b97d-05956b5b58d8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Introduction to the `count()` Function\n",
    "\n",
    "The `count()` function in PySpark is used to count the number of rows in a DataFrame or count the occurrences of specific column values. It is similar to the `COUNT` function in SQL, where you can count all records or count specific columns that meet certain criteria.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49b231c3-aec6-4874-88fd-0fa25fd983ce",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Basic Syntax:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e6b41e37-02dc-4589-8e54-35e98b04c814",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "```\n",
    "DataFrame.count()\n",
    "DataFrame.groupBy(*cols).count()\n",
    "```\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "- **Direct Application**: When `count()` is applied directly on a DataFrame, it returns the total number of rows in the DataFrame.\n",
    "- **With `groupBy()`**: When `count()` is used after `groupBy()`, it counts the occurrences of each group defined by the `groupBy()` columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f66a5c55-84cb-4aea-a058-d1939213c791",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Why Use `count()`?\n",
    "\n",
    "- It is a fundamental function for understanding the size of your data.\n",
    "- Itâ€™s often used to calculate frequencies or counts of records and specific values in data analysis, data profiling, or reporting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4aeb3171-0d14-4c42-90f6-31ba52a7f238",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Practical Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f4833d2-c8b5-44b9-820a-82cb10347bff",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1. Counting Total Rows in a DataFrame\n",
    "\n",
    "**Scenario**: You have a DataFrame with customer data, and you want to count the total number of rows in the DataFrame.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3dc359b-4c2e-44c9-8a19-6f88b83368d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 4\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([\n",
    "    (1, \"John\"),\n",
    "    (2, \"Jane\"),\n",
    "    (3, \"Tom\"),\n",
    "    (4, \"Jerry\")\n",
    "], [\"ID\", \"NAME\"])\n",
    "\n",
    "# Count the total number of rows\n",
    "row_count = df.count()\n",
    "print(f\"Total Rows: {row_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf7c7490-3816-491d-8fe2-13e1f923d084",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2. Counting Non-Null Values in a Column\n",
    "\n",
    "**Scenario**: You want to count the number of non-null values in the `NAME` column.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5790281-6181-4d6e-afa7-17631123abae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-null Names: 3\n"
     ]
    }
   ],
   "source": [
    "df_with_null = spark.createDataFrame([\n",
    "    (1, \"John\"),\n",
    "    (2, \"Jane\"),\n",
    "    (3, None),\n",
    "    (4, \"Jerry\")\n",
    "], [\"ID\", \"NAME\"])\n",
    "\n",
    "# Count non-null values in the \"NAME\" column\n",
    "non_null_count = df_with_null.filter(df_with_null.NAME.isNotNull()).count()\n",
    "print(f\"Non-null Names: {non_null_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05fe91bd-0f5d-4906-b230-8dd0abdd0ba5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3. Counting Unique Values in a Column\n",
    "\n",
    "**Scenario**: You want to count the distinct values in the `NAME` column.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7c8783e-3b90-414a-a2f5-5c727e894c32",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct Names: 4\n"
     ]
    }
   ],
   "source": [
    "# Count distinct values in the \"NAME\" column\n",
    "distinct_count = df_with_null.select(\"NAME\").distinct().count()\n",
    "print(f\"Distinct Names: {distinct_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "526797e4-0f91-4ad8-9d90-c593cdbb72ba",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4. Counting Rows After Grouping\n",
    "\n",
    "**Scenario**: You have a DataFrame with sales data, and you want to group by `ITEM` and count how many times each item appears in the dataset.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d0273ba-e3b5-4eb3-9296-f40a06a63d42",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n| ITEM|count|\n+-----+-----+\n|ItemA|    2|\n|ItemB|    2|\n|ItemC|    1|\n+-----+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df_sales = spark.createDataFrame([\n",
    "    (\"ItemA\", 100),\n",
    "    (\"ItemB\", 200),\n",
    "    (\"ItemA\", 300),\n",
    "    (\"ItemC\", 400),\n",
    "    (\"ItemB\", 500)\n",
    "], [\"ITEM\", \"SALES\"])\n",
    "\n",
    "# Group by ITEM and count the occurrences\n",
    "df_sales.groupBy(\"ITEM\").count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80da1258-65fb-48ab-b980-0661d060d8f0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5. Counting Multiple Columns\n",
    "\n",
    "**Scenario**: You want to count occurrences of each combination of `ITEM` and `SALES`.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a949438-370e-412b-ad16-fe71814f2ab7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+\n| ITEM|SALES|count|\n+-----+-----+-----+\n|ItemA|  100|    1|\n|ItemB|  200|    1|\n|ItemA|  300|    1|\n|ItemC|  400|    1|\n|ItemB|  500|    1|\n+-----+-----+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Group by both ITEM and SALES and count occurrences\n",
    "df_sales.groupBy(\"ITEM\", \"SALES\").count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e89fe762-d667-488e-b9a9-a751090f2a89",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 6. Counting All Columns in the DataFrame\n",
    "\n",
    "**Scenario**: You want to count how many rows each column contains in the entire DataFrame, useful for detecting incomplete or null data.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "824f8779-0e37-408c-848d-3c773b304e24",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n|ITEM|SALES|\n+----+-----+\n|   5|    5|\n+----+-----+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "# Count non-null values for each column\n",
    "df_sales.agg(*[count(col(c)).alias(c) for c in df_sales.columns]).show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "9_pyspark_count_function_count_rows_columns_values",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
