{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "895bb6b0-af3f-41a0-8af0-d1bf40bfbd49",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# PySpark SQL drop() Function: How to Drop Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa718bd7-b33d-4440-87d2-ff17844e8464",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Introduction to the `drop()` Function\n",
    "\n",
    "The `drop()` function in PySpark is used to remove one or more columns from a DataFrame. It is especially useful when you want to clean up your data by eliminating unnecessary columns that are not needed for further processing or analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b37dd678-ca13-4f8f-96c3-24ee38d05d11",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Basic Syntax:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c248111f-270a-4378-b758-369d52822a00",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "```\n",
    "DataFrame.drop(*cols)\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- **`cols`**: The column(s) to be dropped. You can specify one or more column names as strings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2eb52ba-0649-4207-912a-972e71dd4b40",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## How It Works:\n",
    "\n",
    "- When you call `drop()`, it returns a new DataFrame with the specified columns removed. The original DataFrame remains unchanged unless reassigned.\n",
    "- You can drop multiple columns at once by passing multiple column names to the `drop()` function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b745819-157d-4dee-9f61-c3c0512e12f8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Practical Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54e3b98c-8735-4030-b070-0180a4ca15c3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1. Dropping a Single Column\n",
    "\n",
    "**Scenario**: You have a DataFrame with employee data, and you want to drop the `EMAIL` column since it’s not needed for your analysis.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "733ba856-c4d6-46ec-a91d-384d5834d5c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+------+\n|EMPLOYEE_ID|NAME|SALARY|\n+-----------+----+------+\n|          1|John|  3000|\n|          2|Jane|  4000|\n|          3| Tom|  3500|\n+-----------+----+------+\n\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([\n",
    "    (1, \"John\", \"john@example.com\", 3000),\n",
    "    (2, \"Jane\", \"jane@example.com\", 4000),\n",
    "    (3, \"Tom\", \"tom@example.com\", 3500)\n",
    "], [\"EMPLOYEE_ID\", \"NAME\", \"EMAIL\", \"SALARY\"])\n",
    "\n",
    "# Drop the \"EMAIL\" column\n",
    "df.drop(\"EMAIL\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd05ff5a-3875-4f30-b939-7e8a3e1e0c48",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2. Dropping Multiple Columns\n",
    "\n",
    "**Scenario**: You want to drop both the `EMAIL` and `SALARY` columns from the employee DataFrame.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bc14d13-00b4-4bb3-8ef7-da8d109713c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+\n|EMPLOYEE_ID|NAME|\n+-----------+----+\n|          1|John|\n|          2|Jane|\n|          3| Tom|\n+-----------+----+\n\n"
     ]
    }
   ],
   "source": [
    "# Drop multiple columns \"EMAIL\" and \"SALARY\"\n",
    "df.drop(\"EMAIL\", \"SALARY\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b8eb0b9-0319-49b6-ac5a-b1f0b9afc59c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3. Handling Non-Existent Columns\n",
    "\n",
    "**Scenario**: You attempt to drop a column that doesn’t exist, such as `ADDRESS`. PySpark will simply ignore the non-existent column and drop only the ones that are valid.\n",
    "\n",
    "**Code Example**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "851fc291-832e-4b23-ac7a-6f442c1832a1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+------+\n|EMPLOYEE_ID|NAME|SALARY|\n+-----------+----+------+\n|          1|John|  3000|\n|          2|Jane|  4000|\n|          3| Tom|  3500|\n+-----------+----+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Attempt to drop non-existent column \"ADDRESS\"\n",
    "df.drop(\"ADDRESS\", \"EMAIL\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ff64a1a-e77c-48e4-8e20-e51b6ccb5a5e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4. Dropping Columns in a Loop\n",
    "\n",
    "**Scenario**: You have a list of columns to drop, and you want to remove them dynamically in a loop.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "baac183a-227e-4ec7-9070-90090d4c013d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+\n|EMPLOYEE_ID|NAME|\n+-----------+----+\n|          1|John|\n|          2|Jane|\n|          3| Tom|\n+-----------+----+\n\n"
     ]
    }
   ],
   "source": [
    "# List of columns to drop\n",
    "cols_to_drop = [\"EMAIL\", \"SALARY\"]\n",
    "\n",
    "# Drop columns dynamically using a loop\n",
    "for col in cols_to_drop:\n",
    "    df = df.drop(col)\n",
    "\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4f8986d-94b6-412b-be71-63c08ac2df71",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5. Dropping Columns Using a Condition (Advanced)\n",
    "\n",
    "**Scenario**: You want to drop all columns where the data type is `string`. This can be useful when you’re only interested in numerical columns for a certain analysis.\n",
    "\n",
    "**Code Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8aed0a3e-84d6-474c-998c-77a4152f4fd6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n|EMPLOYEE_ID|SALARY|\n+-----------+------+\n|          1|  3000|\n|          2|  4000|\n|          3|  3500|\n+-----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Drop columns where data type is string\n",
    "string_cols = [col for col, dtype in df.dtypes if dtype == 'string']\n",
    "\n",
    "df.drop(*string_cols).show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "5_pyspark_drop_function_how_to_drop_columns",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
